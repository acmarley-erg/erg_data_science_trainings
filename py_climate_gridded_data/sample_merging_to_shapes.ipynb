{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import datetime\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "base = '/pool001/vilgalys/inferring_expectations/'\n",
    "\n",
    "geospatial_resolution = 0.041666666666666\n",
    "min_dist = geospatial_resolution / np.sqrt(2)\n",
    "\n",
    "\"\"\" \n",
    "Read files from all utilities \n",
    "\"\"\"\n",
    "ica_gdb = gpd.read_file(base + 'data/all_ica_maps/')\n",
    "ica_gdb.head()\n",
    "ica_lat_lon = ica_gdb.to_crs(\"EPSG:4326\")\n",
    "ica_lat_lon.head()\n",
    "\n",
    "nws = gpd.read_file(base + 'data/nws_gdb')\n",
    "def contime(text):\n",
    "    \"\"\"Convert text into a UTC datetime.\"\"\"\n",
    "    if text is None: return None\n",
    "    # The 0000 is the standard VTEC undefined time\n",
    "    if text.startswith(\"0000\"):\n",
    "        return None\n",
    "    ts = datetime.datetime.strptime(text, \"%Y%m%d%H%M\")\n",
    "    # NWS has a bug sometimes whereby 1969 or 1970s timestamps are emitted\n",
    "    return ts\n",
    "nws = nws[nws.PHENOM == 'FW']\n",
    "nws['issued'] = nws['ISSUED'].apply(contime)\n",
    "nws['expired'] = nws['EXPIRED'].apply(contime)\n",
    "nws['init_exp'] = nws['INIT_EXP'].apply(contime)\n",
    "nws['init_iss'] = nws['INIT_ISS'].apply(contime)\n",
    "nws = nws.to_crs(epsg=4326)\n",
    "nws['start_date'] = (np.minimum(nws.init_iss.dt.date, nws.issued.dt.date).apply(pd.to_datetime) - datetime.datetime(1900,1,1)).dt.days\n",
    "nws['end_date'] = (np.maximum(nws.init_exp.dt.date, nws.expired.dt.date).apply(pd.to_datetime) - datetime.datetime(1900,1,1)).dt.days\n",
    "nws.head()\n",
    "\n",
    "# make geodatabase of all points in california \n",
    "elevation_fp = base + 'data/gridmet/cal_elevationdata.nc'\n",
    "elevation_ds = nc.Dataset(elevation_fp, 'r')\n",
    "x_orig, y_orig = np.meshgrid(elevation_ds['lat'], elevation_ds['lon'], indexing='ij')\n",
    "x, y = x_orig.flatten(), y_orig.flatten()\n",
    "orig_shape = elevation_ds['elevation'].shape\n",
    "width = geospatial_resolution / 2\n",
    "s = gpd.GeoSeries([MultiPoint([[_y - width, _x - width], [_y + width, _x + width]]).envelope for _x, _y in zip(x, y)])\n",
    "\n",
    "\n",
    "prefixes = ['sph','vpd','pr','rmin','rmax','srad','tmmn','tmmx','vs','th','pet',\n",
    "            'etr','fm100','fm1000','bi','erc','pdsi']\n",
    "# prefixes = ['pdsi', 'sph', 'vpd', 'pr']\n",
    "ds_dict = {}\n",
    "mask_dict = {}\n",
    "time_series = None\n",
    "for prefix in prefixes:\n",
    "    ds = nc.Dataset(base + \\\n",
    "                    'data/gridmet/cal_{}.nc'.format(prefix + '_full' if prefix == 'pdsi' else prefix), 'r')\n",
    "    if time_series is None:\n",
    "        time_series = ds['day'][:]\n",
    "    else:\n",
    "        assert all(time_series == ds['day'][:])\n",
    "    varname = list(ds.variables)[-1]\n",
    "    mask_dict[prefix] = ds[varname][:].mask\n",
    "    ds_dict[prefix] = np.array(ds[varname][:])\n",
    "    ds.close()\n",
    "time_series = pd.Series(time_series)\n",
    "\n",
    "out_fp = '/nobackup1/vilgalys/gridmet_red_flag_circuits.csv'\n",
    "if os.path.exists(out_fp):\n",
    "    os.remove(out_fp)\n",
    "file_exists = False\n",
    "# Read all of the datasupply things separately! \n",
    "# Maybe get subsets of them since we started seeing records of Red Flag warnings? \n",
    "# The intersection of this plus red flags might be another whole big thing \n",
    "\n",
    "for i, row in ica_lat_lon.iterrows():\n",
    "    fire_warnings = nws[nws.intersects(row.geometry)]\n",
    "    if len(fire_warnings) == 0: \n",
    "        fire_dates = []\n",
    "    else:\n",
    "        fire_dates = np.arange(np.min(fire_warnings['start_date']), np.max(fire_warnings['end_date'] + 1))\n",
    "        fire_dates = fire_dates[[any((date >= fire_warnings.start_date) & (date <= fire_warnings.end_date)) for date in fire_dates]]\n",
    "    zero_dist_matches = np.where(s.distance(row.geometry) == 0)\n",
    "    overlap = np.zeros(len(s))\n",
    "    overlap[zero_dist_matches] = s.iloc[zero_dist_matches].intersection(row.geometry).length\n",
    "    overlap = overlap.reshape(orig_shape)\n",
    "    overall_df = None\n",
    "    date_range = time_series.isin(fire_dates).values\n",
    "    for prefix, ds in ds_dict.items():\n",
    "        mask = mask_dict[prefix][0,...]\n",
    "        mask_overlap = np.multiply(overlap.copy(), ~mask)\n",
    "        mask_overlap = mask_overlap.flatten()\n",
    "        flat_vals = ds.reshape((ds.shape[0], -1))\n",
    "        means = np.tensordot(flat_vals, mask_overlap, axes=1) / np.sum(mask_overlap)\n",
    "        means = means.reshape(-1,1)\n",
    "        # means = means[date_range, ...]\n",
    "        sub_df = pd.DataFrame(means,columns = [prefix])\n",
    "        sub_df['date'] = time_series\n",
    "        sub_df = sub_df[sub_df['date'] >= 41273] # Excludes values before 1/1/2013\n",
    "        # sub_df['date'] = [datetime.date(1900,1,1) + \\\n",
    "        #         datetime.timedelta(int(d)) for d in time_series]# [date_range]]\n",
    "        # sub_df = sub_df[sub_df.date >= datetime.date(2013,1,1)]\n",
    "        sub_df = sub_df.set_index('date')\n",
    "        if overall_df is None:\n",
    "            overall_df = sub_df\n",
    "        else:\n",
    "            overall_df = overall_df.merge(sub_df, left_index=True, right_index=True, how='outer')\n",
    "    overall_df = overall_df.reset_index()\n",
    "    overall_df['red_flag'] = overall_df.date.isin(fire_dates).values\n",
    "    overall_df['date'] = [datetime.date(1900,1,1) + \\\n",
    "                datetime.timedelta(int(d)) for d in overall_df['date']]\n",
    "    overall_df['clean_name'] = row['clean_name']\n",
    "    overall_df['Utility'] = row['Utility']\n",
    "    overall_df['elevation'] = np.dot(elevation_ds['elevation'][...].reshape(-1), mask_overlap) / np.sum(mask_overlap)\n",
    "    overall_df.to_csv(out_fp, mode='a',index=False, header=~file_exists)\n",
    "    file_exists = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
